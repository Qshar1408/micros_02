
# Домашнее задание к занятию «Микросервисы: принципы»

### Грибанов Антон. FOPS-31

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: API Gateway 

Предложите решение для обеспечения реализации API Gateway. Составьте сравнительную таблицу возможностей различных программных решений. На основе таблицы сделайте выбор решения.

Решение должно соответствовать следующим требованиям:
- маршрутизация запросов к нужному сервису на основе конфигурации,
- возможность проверки аутентификационной информации в запросах,
- обеспечение терминации HTTPS.

Обоснуйте свой выбор.

### Решение:

#### Предложение по организации инфраструктуры с использованием API Gateway

**Концепция:** Мы предлагаем внедрить **API Gateway как единую точку входа ("главный вход")** для всех обращений к нашей системе. Это специальная программа, которая принимает все запросы от пользователей и приложений и "разводит" их по нужным внутренним сервисам (микросервисам), обеспечивая безопасность и надежность.

**Роль в инфраструктуре:**
*   **Для разработки:** Разработчики запускают Gateway на своих компьютерах или на общем сервере для тестирования. Gateway направляет их запросы к локальным версиям сервисов, позволяя работать в условиях, максимально приближенным к реальным.
*   **Для эксплуатации:** Gateway работает на выделенных, мощных серверах (или кластере серверов) "на границе" нашей сети. Весь внешний трафик сначала попадает на него, и только потом, после проверки, — на внутренние сервисы.

---

### Сравнительная таблица программных решений для API Gateway

Мы сравним популярные решения, которые можно установить на свои серверы, и одно облачное.

| Критерий / Решение | **Kong Gateway** | **Traefik** | **NGINX** | **AWS API Gateway** |
| :--- | :--- | :--- | :--- | :--- |
| **1. Маршрутизация запросов** | **Отлично.** Говорит: "Запрос на `/api/users/*` отправляй на сервер `сервис-пользователей:8080`". Гибкие правила по пути, домену и др. | **Отлично.** Особенно силен в автоматическом обнаружении: "Появился новый сервис — я уже маршрутизирую к нему!" | **Очень хорошо.** Классический, надежный. Правила пишутся в конфиг-файле. Мощный, но требует ручной настройки. | **Отлично.** Настройка через веб-интерфейс AWS. Правила создаются легко и наглядно. |
| **2. Проверка аутентификации** | **Отлично.** Есть встроенные "модули" (плагины) для проверки логинов/паролей, JWT-токенов и других методов. Включил — и он сам проверяет каждый запрос. | **Хорошо.** Базовая проверка токенов есть. Для сложных сценариев (через Google/Facebook) может понадобиться платная версия. | **Сложно.** Сам по себе не умеет. Нужно писать специальные скрипты или направлять запросы на отдельный сервис аутентификации. | **Отлично.** Встроенная интеграция с сервисами авторизации AWS. Просто выбираешь в настройках. |
| **3. Терминация HTTPS** | **Отлично.** Умеет работать с HTTPS-сертификатами, в т.ч. автоматически их обновлять. | **Отлично.** Мастер автоматического обновления сертификатов. Сам получает и подставляет их. | **Очень хорошо.** Отлично поддерживает HTTPS, но автоматизацию нужно настраивать дополнительными инструментами. | **Отлично.** Сервис сам заботится о сертификатах. Вы просто включаете HTTPS. |
| **Простота управления** | **Средняя.** Нужно понимать его API или формат конфиг-файлов. Требует отдельной базы данных (PostgreSQL). | **Высокая.** Прост в начальной настройке, особенно если сервисы часто меняются. Конфигурация через файлы или метки. | **Низкая.** Требует глубокого знания синтаксиса его конфигов. Администрирование сложнее. | **Очень высокая.** Все управляется через удобную веб-консоль. Не нужно думать о серверах. |
| **Где работает?** | На ваших серверах | На ваших серверах | На ваших серверах | В облаке AWS (управляемый сервис) |
| **Стоимость** | Бесплатно (Open-Source) | Бесплатно (Open-Source) | Бесплатно (Open Source) | Платная (плата за количество вызовов). Может стать дорогой. |
| **Главное преимущество** | Богатейший набор встроенных функций (без программирования) | Простота и автоматизация | Скорость, надежность и стабильность | Полное отсутствие забот об администрировании |

---

### Выбор и обоснование

На основе анализа таблицы и ваших требований, я рекомендую использовать **Kong Gateway**.

**Почему Kong — лучший выбор для нас?**

1.  **Полное и "из коробки" соответствие всем требованиям:**
    *   **Маршрутизация:** Умеет гибко направлять запросы по простым и понятным правилам. Мы легко опишем, какой запрос куда должен идти.
    *   **Аутентификация:** Это ключевое преимущество. У Kong есть **готовый встроенный модуль для проверки JWT-токенов**. Нам не нужно писать свой код или разворачивать дополнительные сервисы для этой задачи. Мы просто включаем этот плагин в настройках Gateway — и он сам начнет проверять подпись и валидность каждого токена. Это напрямую, легко и надежно закрывает **требование №2**.
    *   **HTTPS:** Имеет все необходимые инструменты для работы с HTTPS-сертификатами, включая возможность их автоматического обновления.

2.  **Мощь без чрезмерной сложности:** Да, ему нужна база данных для хранения конфигураций, но это плата за надежность и возможность централизованного управления. Взамен мы получаем продукт корпоративного уровня с огромным количеством готовых функций (например, для ограничения числа запросов, логирования, кеширования), которые нам могут понадобиться в будущем.

3.  **Избегаем "привязки к вендору":** Используя Kong на своих серверах, мы сохраняем полный контроль над инфраструктурой. Мы не зависим от AWS и можем при необходимости перенести всю систему в другое облако или в собственный дата-центр. Решение на основе AWS API Gateway навсегда привяжет нас к Amazon.

**Почему не другие варианты в нашем случае?**

*   **Traefik:** Очень простой и современный, но его возможности по проверке аутентификации в бесплатной версии ограничены. Нам пришлось бы либо покупать платную версию, либо "изобретать велосипед", что делает его менее подходящим для наших конкретных требований.
*   **NGINX:** Это как собрать машину из запчастей. NGINX — великолепный двигатель, но для создания из него полноценного API Gateway нам придется самостоятельно писать скрипты для аутентификации. Это увеличивает время разработки, сложность поддержки и риск ошибок.
*   **AWS API Gateway:** Это "палка о двух концах". С одной стороны — простота, с другой — зависимость от AWS и растущие затраты. Для крупной компании, которая строит долгосрочную и гибкую архитектуру, такая привязка нежелательна.

### Как это будет работать (простыми словами)

1.  **Развертывание:** Мы устанавливаем программу Kong на один или несколько надежных серверов с Linux.
2.  **Настройка:** Через API или конфигурационные файлы мы говорим Kong:
    *   *"Все запросы, которые приходят на адрес `api.our-company.com/users`, перенаправляй на внутренний сервер `10.0.1.10:8080`".*
    *   *"На всех маршрутах, кроме `/auth`, включи плагин `jwt`".* (Теперь Kong будет проверять токен у каждого запроса).
    *   *"Используй вот этот SSL-сертификат для шифрования".*
3.  **В работе:**
    *   Пользователь отправляет запрос `https://api.our-company.com/orders`.
    *   Запрос приходит на сервер Kong.
    *   **Kong проверяет HTTPS.** -> **Требование 3 выполнено.**
    *   **Kong проверяет JWT-токен в заголовке запроса.** -> **Требование 2 выполнено.**
    *   Если токен валидный, **Kong смотрит, что путь `/orders` ведет к сервису `сервис-заказов`**, и перенаправляет туда запрос. -> **Требование 1 выполнено.**
    *   Сервис заказов обрабатывает запрос и возвращает ответ через Kong обратно пользователю.

**Заключение:**

**Kong Gateway** предлагает идеальный баланс между мощностью, наличием готовых критически важных функций (особенно для аутентификации) и возможностью работать на нашей собственной инфраструктуре. Он позволяет нам сразу решить все поставленные задачи без лишней сложности и без привязки к облачному провайдеру.

## Задача 2: Брокер сообщений

Составьте таблицу возможностей различных брокеров сообщений. На основе таблицы сделайте обоснованный выбор решения.

Решение должно соответствовать следующим требованиям:
- поддержка кластеризации для обеспечения надёжности,
- хранение сообщений на диске в процессе доставки,
- высокая скорость работы,
- поддержка различных форматов сообщений,
- разделение прав доступа к различным потокам сообщений,
- простота эксплуатации.

Обоснуйте свой выбор.

## Задача 3: API Gateway * (необязательная)

### Есть три сервиса:

**minio**
- хранит загруженные файлы в бакете images,
- S3 протокол,

**uploader**
- принимает файл, если картинка сжимает и загружает его в minio,
- POST /v1/upload,

**security**
- регистрация пользователя POST /v1/user,
- получение информации о пользователе GET /v1/user,
- логин пользователя POST /v1/token,
- проверка токена GET /v1/token/validation.

### Необходимо воспользоваться любым балансировщиком и сделать API Gateway:

**POST /v1/register**
1. Анонимный доступ.
2. Запрос направляется в сервис security POST /v1/user.

**POST /v1/token**
1. Анонимный доступ.
2. Запрос направляется в сервис security POST /v1/token.

**GET /v1/user**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис security GET /v1/user.

**POST /v1/upload**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис uploader POST /v1/upload.

**GET /v1/user/{image}**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис minio GET /images/{image}.

### Ожидаемый результат

Результатом выполнения задачи должен быть docker compose файл, запустив который можно локально выполнить следующие команды с успешным результатом.
Предполагается, что для реализации API Gateway будет написан конфиг для NGinx или другого балансировщика нагрузки, который будет запущен как сервис через docker-compose и будет обеспечивать балансировку и проверку аутентификации входящих запросов.
Авторизация
curl -X POST -H 'Content-Type: application/json' -d '{"login":"bob", "password":"qwe123"}' http://localhost/token

**Загрузка файла**

curl -X POST -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJib2IifQ.hiMVLmssoTsy1MqbmIoviDeFPvo-nCd92d4UFiN2O2I' -H 'Content-Type: octet/stream' --data-binary @yourfilename.jpg http://localhost/upload

**Получение файла**
curl -X GET http://localhost/images/4e6df220-295e-4231-82bc-45e4b1484430.jpg

---
