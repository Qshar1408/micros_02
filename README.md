
# Домашнее задание к занятию «Микросервисы: принципы»

### Грибанов Антон. FOPS-31

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: API Gateway 

Предложите решение для обеспечения реализации API Gateway. Составьте сравнительную таблицу возможностей различных программных решений. На основе таблицы сделайте выбор решения.

Решение должно соответствовать следующим требованиям:
- маршрутизация запросов к нужному сервису на основе конфигурации,
- возможность проверки аутентификационной информации в запросах,
- обеспечение терминации HTTPS.

Обоснуйте свой выбор.

### Решение:

#### Предложение по организации инфраструктуры с использованием API Gateway

**Концепция:** Как DevOps-специалисту, я предлагаю внедрить **API Gateway как единую точку входа ("главный вход")** для всех обращений к нашей системе. Это специальная программа, которая принимает все запросы от пользователей и приложений и "разводит" их по нужным внутренним сервисам (микросервисам), обеспечивая безопасность и надежность.

**Роль в инфраструктуре:**
*   **Для разработки:** Разработчики запускают Gateway на своих компьютерах или на общем сервере для тестирования. Gateway направляет их запросы к локальным версиям сервисов, позволяя работать в условиях, максимально приближенным к реальным.
*   **Для эксплуатации:** Gateway работает на выделенных, мощных серверах (или кластере серверов) "на границе" нашей сети. Весь внешний трафик сначала попадает на него, и только потом, после проверки, — на внутренние сервисы.

---

### Сравнительная таблица программных решений для API Gateway

На основании найденной информации в сети-интернет и открытых информационных источников, сравним популярные решения, которые можно установить на свои серверы, и одно облачное.

| Критерий / Решение | **Kong Gateway** | **Traefik** | **NGINX** | **AWS API Gateway** |
| :--- | :--- | :--- | :--- | :--- |
| **1. Маршрутизация запросов** | **Отлично.** Говорит: "Запрос на `/api/users/*` отправляй на сервер `сервис-пользователей:8080`". Гибкие правила по пути, домену и др. | **Отлично.** Особенно силен в автоматическом обнаружении: "Появился новый сервис — я уже маршрутизирую к нему!" | **Очень хорошо.** Классический, надежный. Правила пишутся в конфиг-файле. Мощный, но требует ручной настройки. | **Отлично.** Настройка через веб-интерфейс AWS. Правила создаются легко и наглядно. |
| **2. Проверка аутентификации** | **Отлично.** Есть встроенные "модули" (плагины) для проверки логинов/паролей, JWT-токенов и других методов. Включил — и он сам проверяет каждый запрос. | **Хорошо.** Базовая проверка токенов есть. Для сложных сценариев (через Google/Facebook) может понадобиться платная версия. | **Сложно.** Сам по себе не умеет. Нужно писать специальные скрипты или направлять запросы на отдельный сервис аутентификации. | **Отлично.** Встроенная интеграция с сервисами авторизации AWS. Просто выбираешь в настройках. |
| **3. Терминация HTTPS** | **Отлично.** Умеет работать с HTTPS-сертификатами, в т.ч. автоматически их обновлять. | **Отлично.** Мастер автоматического обновления сертификатов. Сам получает и подставляет их. | **Очень хорошо.** Отлично поддерживает HTTPS, но автоматизацию нужно настраивать дополнительными инструментами. | **Отлично.** Сервис сам заботится о сертификатах. Вы просто включаете HTTPS. |
| **Простота управления** | **Средняя.** Нужно понимать его API или формат конфиг-файлов. Требует отдельной базы данных (PostgreSQL). | **Высокая.** Прост в начальной настройке, особенно если сервисы часто меняются. Конфигурация через файлы или метки. | **Низкая.** Требует глубокого знания синтаксиса его конфигов. Администрирование сложнее. | **Очень высокая.** Все управляется через удобную веб-консоль. Не нужно думать о серверах. |
| **Где работает?** | На ваших серверах | На ваших серверах | На ваших серверах | В облаке AWS (управляемый сервис) |
| **Стоимость** | Бесплатно (Open-Source) | Бесплатно (Open-Source) | Бесплатно (Open Source) | Платная (плата за количество вызовов). Может стать дорогой. |
| **Главное преимущество** | Богатейший набор встроенных функций (без программирования) | Простота и автоматизация | Скорость, надежность и стабильность | Полное отсутствие забот об администрировании |

---

### Выбор и обоснование

На основе анализа таблицы и исходных требований, мне кажется рациональным использовать **Kong Gateway**.

**Почему Kong — лучший выбор для нас?**

1.  **Полное и "из коробки" соответствие всем требованиям:**
    *   **Маршрутизация:** Умеет гибко направлять запросы по простым и понятным правилам. Мы легко опишем, какой запрос куда должен идти.
    *   **Аутентификация:** Это ключевое преимущество. У Kong есть **готовый встроенный модуль для проверки JWT-токенов**. Нам не нужно писать свой код или разворачивать дополнительные сервисы для этой задачи. Мы просто включаем этот плагин в настройках Gateway — и он сам начнет проверять подпись и валидность каждого токена. Это напрямую, легко и надежно закрывает **требование №2**.
    *   **HTTPS:** Имеет все необходимые инструменты для работы с HTTPS-сертификатами, включая возможность их автоматического обновления.

2.  **Мощь без чрезмерной сложности:** Да, ему нужна база данных для хранения конфигураций, но это плата за надежность и возможность централизованного управления. Взамен мы получаем продукт корпоративного уровня с огромным количеством готовых функций (например, для ограничения числа запросов, логирования, кеширования), которые нам могут понадобиться в будущем.

3.  **Избегаем "привязки к вендору":** Используя Kong на своих серверах, мы сохраняем полный контроль над инфраструктурой. Мы не зависим от AWS и можем при необходимости перенести всю систему в другое облако или в собственный дата-центр. Решение на основе AWS API Gateway навсегда привяжет нас к Amazon.

**Почему не другие варианты в нашем случае?**

*   **Traefik:** Очень простой и современный, но его возможности по проверке аутентификации в бесплатной версии ограничены. Нам пришлось бы либо покупать платную версию, либо "изобретать велосипед", что делает его менее подходящим для наших конкретных требований.
*   **NGINX:** Это как собрать машину из запчастей. NGINX — великолепный двигатель, но для создания из него полноценного API Gateway нам придется самостоятельно писать скрипты для аутентификации. Это увеличивает время разработки, сложность поддержки и риск ошибок.
*   **AWS API Gateway:** Это "палка о двух концах". С одной стороны — простота, с другой — зависимость от AWS и растущие затраты. Для крупной компании, которая строит долгосрочную и гибкую архитектуру, такая привязка нежелательна.

### Как это будет работать (простыми словами)

1.  **Развертывание:** Мы устанавливаем программу Kong на один или несколько надежных серверов с Linux.
2.  **Настройка:** Через API или конфигурационные файлы мы говорим Kong:
    *   *"Все запросы, которые приходят на адрес `api.our-company.com/users`, перенаправляй на внутренний сервер `10.0.1.10:8080`".*
    *   *"На всех маршрутах, кроме `/auth`, включи плагин `jwt`".* (Теперь Kong будет проверять токен у каждого запроса).
    *   *"Используй вот этот SSL-сертификат для шифрования".*
3.  **В работе:**
    *   Пользователь отправляет запрос `https://api.our-company.com/orders`.
    *   Запрос приходит на сервер Kong.
    *   **Kong проверяет HTTPS.** -> **Требование 3 выполнено.**
    *   **Kong проверяет JWT-токен в заголовке запроса.** -> **Требование 2 выполнено.**
    *   Если токен валидный, **Kong смотрит, что путь `/orders` ведет к сервису `сервис-заказов`**, и перенаправляет туда запрос. -> **Требование 1 выполнено.**
    *   Сервис заказов обрабатывает запрос и возвращает ответ через Kong обратно пользователю.

**Заключение:**

**Kong Gateway** предлагает идеальный баланс между мощностью, наличием готовых критически важных функций (особенно для аутентификации) и возможностью работать на нашей собственной инфраструктуре. Он позволяет нам сразу решить все поставленные задачи без лишней сложности и без привязки к облачному провайдеру.

## Задача 2: Брокер сообщений

Составьте таблицу возможностей различных брокеров сообщений. На основе таблицы сделайте обоснованный выбор решения.

Решение должно соответствовать следующим требованиям:
- поддержка кластеризации для обеспечения надёжности,
- хранение сообщений на диске в процессе доставки,
- высокая скорость работы,
- поддержка различных форматов сообщений,
- разделение прав доступа к различным потокам сообщений,
- простота эксплуатации.

Обоснуйте свой выбор.

### Решение:

#### Предложение по выбору брокера сообщений для микросервисной архитектуры

##### Сравнительная таблица брокеров сообщений

| Критерий / Решение | **Apache Kafka** | **RabbitMQ** | **NATS** | **Redis Pub/Sub** | **Apache Pulsar** |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **1. Поддержка кластеризации** | **Отлично.** Встроенная отказоустойчивая кластеризация, репликация данных | **Отлично.** Кластеризация через mirrored queues, высокий уровень надежности | **Хорошо.** Кластерный режим с репликацией, проще в настройке чем Kafka | **Ограничено.** Redis Cluster для ключей, но Pub/Sub работает в пределах ноды | **Отлично.** Многоуровневая архитектура, встроенная кластеризация |
| **2. Хранение на диске** | **Отлично.** Все сообщения хранятся на диске, настраиваемое время хранения | **Отлично.** Сообщения можно сохранять на диск (persistent messages) | **Зависит.** NATS Streaming - да, NATS JetStream - да, базовый NATS - нет | **Нет.** Сообщения теряются при перезагрузке | **Отлично.** Сегментированное хранение, многоуровневое хранение |
| **3. Скорость работы** | **Очень высокая.** Оптимизирован для throughput, задержки ~10-100ms | **Высокая.** ~50k сообщений/сек на одной ноде, задержки ~100μs-1ms | **Экстремальная.** ~1M+ сообщений/сек, задержки ~10-200μs | **Очень высокая.** ~1M+ сообщений/сек, но только в памяти | **Высокая.** ~100k-1M сообщений/сек, низкие задержки |
| **4. Форматы сообщений** | **Гибко.** Любой бинарный формат (JSON, Avro, Protobuf на стороне клиента) | **Гибко.** Любой формат, content-type заголовки | **Гибко.** Любой бинарный формат, аналогично Kafka | **Ограничено.** Только строки/бинарные данные, структура на клиенте | **Гибко.** Поддержка различных форматов, schema registry |
| **5. Разделение прав доступа** | **Отлично.** SASL, SSL, ACL, интеграция с внешними системами аутентификации | **Отлично.** Vhost, users, permissions, детальное управление правами | **Базово.** Аутентификация, авторизация через JWTs, менее гибкое чем у конкурентов | **Слабо.** Только парольная аутентификация, нет fine-grained ACL | **Отлично.** Namespaces, topics, детальные ACL, RBAC |
| **6. Простота эксплуатации** | **Сложно.** Требует Zookeeper, сложная настройка и мониторинг | **Просто.** Легко настраивать и администрировать, хорошие инструменты | **Очень просто.** Минимальная конфигурация, легкий вес | **Очень просто.** Простая установка и настройка | **Средне.** Проще чем Kafka, но сложнее чем RabbitMQ |
| **Модель доставки** | Pub/Sub, Log | Pub/Sub, Message Queues | Pub/Sub, Request-Reply | Pub/Sub | Pub/Sub, Message Queues |
| **Гарантии доставки** | At-least-once, Exactly-once | At-most-once, At-least-once | At-most-once, At-least-once (Streaming) | At-most-once | At-least-once, Exactly-once |
| **Экосистема** | **Очень богатая.** Kafka Connect, Streams, множество коннекторов | **Богатая.** Множество плагинов и клиентов | **Растущая.** Активно развивающаяся экосистема | **Богатая.** Много клиентов, но ограничено функциями | **Развивающаяся.** Активно растущая экосистема |

#### Рекомендуемое решение: RabbitMQ

#### Обоснование выбора

**RabbitMQ** выбран как наиболее сбалансированное решение, оптимально соответствующее всем требованиям:

#### Соответствие требованиям

1. **✅ Поддержка кластеризации** - Встроенная кластеризация с mirrored queues обеспечивает отказоустойчивость и надежность
2. **✅ Хранение на диске** - Persistent messages гарантируют сохранность данных при перезагрузках
3. **✅ Высокая скорость** - До 50k сообщений/сек на ноде достаточно для большинства enterprise-нагрузок
4. **✅ Форматы сообщений** - Поддержка любых форматов через content-type заголовки
5. **✅ Разделение прав доступа** - Детальная система прав через vhost, users, permissions
6. **✅ Простота эксплуатации** - Простая установка, настройка и мониторинг через Web UI

#### Преимущества RabbitMQ для компании

**Операционная эффективность:**
- Простота развертывания и обслуживания снижает TCO
- Интуитивная веб-панель управления для мониторинга
- Широкая документация и большое сообщество

**Надежность и безопасность:**
- Гарантированная доставка сообщений
- Дисковая персистентность критичных данных
- Детальное управление доступом для compliance требований

**Гибкость архитектуры:**
- Поддержка различных паттернов (Pub/Sub, Work Queues, RPC)
- Плавное обучение команды благодаря понятной модели
- Легкая интеграция с существующими системами

#### Почему не другие решения?

- **Kafka** - Слишком сложен в эксплуатации, избыточен для большинства сценариев
- **NATS** - Ограниченные возможности персистентности и управления правами
- **Redis** - Отсутствие гарантий доставки и хранения на диске
- **Pulsar** - Молодая экосистема, меньшая стабильность в production

#### Архитектура развертывания

```
[Микросервисы] → [Cluster RabbitMQ] → [Микросервисы]
    ↑                    ↑                    ↑
 3 ноды + Load Balancer, mirrored queues, мониторинг
```

#### План внедрения

1. **Этап 1:** Развертывание 3-нодного кластера RabbitMQ
2. **Этап 2:** Настройка mirrored queues для критичных данных
3. **Этап 3:** Конфигурация системы аутентификации и авторизации
4. **Этап 4:** Интеграция с мониторинг и alerting системами
5. **Этап 5:** Миграция сервисов на новую платформу

**Заключение:** RabbitMQ предлагает оптимальный баланс между функциональностью, надежностью и простотой эксплуатации, что делает его идеальным выбором для микросервисной архитектуры компании.


### Задача 3: API Gateway * (необязательная)

### Есть три сервиса:

**minio**
- хранит загруженные файлы в бакете images,
- S3 протокол,

**uploader**
- принимает файл, если картинка сжимает и загружает его в minio,
- POST /v1/upload,

**security**
- регистрация пользователя POST /v1/user,
- получение информации о пользователе GET /v1/user,
- логин пользователя POST /v1/token,
- проверка токена GET /v1/token/validation.

### Необходимо воспользоваться любым балансировщиком и сделать API Gateway:

**POST /v1/register**
1. Анонимный доступ.
2. Запрос направляется в сервис security POST /v1/user.

**POST /v1/token**
1. Анонимный доступ.
2. Запрос направляется в сервис security POST /v1/token.

**GET /v1/user**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис security GET /v1/user.

**POST /v1/upload**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис uploader POST /v1/upload.

**GET /v1/user/{image}**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис minio GET /images/{image}.

### Ожидаемый результат

Результатом выполнения задачи должен быть docker compose файл, запустив который можно локально выполнить следующие команды с успешным результатом.
Предполагается, что для реализации API Gateway будет написан конфиг для NGinx или другого балансировщика нагрузки, который будет запущен как сервис через docker-compose и будет обеспечивать балансировку и проверку аутентификации входящих запросов.
Авторизация
curl -X POST -H 'Content-Type: application/json' -d '{"login":"bob", "password":"qwe123"}' http://localhost/token

**Загрузка файла**

curl -X POST -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJib2IifQ.hiMVLmssoTsy1MqbmIoviDeFPvo-nCd92d4UFiN2O2I' -H 'Content-Type: octet/stream' --data-binary @yourfilename.jpg http://localhost/upload

**Получение файла**
curl -X GET http://localhost/images/4e6df220-295e-4231-82bc-45e4b1484430.jpg

---
